{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ensemble Model - Combining U-Net and Mask R-CNN\n",
        "\n",
        "This notebook implements an ensemble approach that combines predictions from both U-Net and Mask R-CNN models for improved traffic sign detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")\n",
        "print(f\"GPU available: {len(tf.config.list_physical_devices('GPU')) > 0}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_PATH = \"../data/car\"\n",
        "UNET_MODEL_PATH = \"../data/models/full_dataset_model_traffic_sign_unet.h5\"\n",
        "MASKRCNN_MODEL_PATH = \"final_maskrcnn_model.h5\"\n",
        "RESULTS_PATH = \"../data/results\"\n",
        "\n",
        "UNET_IMG_SIZE = (256, 256)\n",
        "MASKRCNN_IMG_SIZE = (128, 128)\n",
        "\n",
        "os.makedirs(RESULTS_PATH, exist_ok=True)\n",
        "\n",
        "print(f\"Data path exists: {os.path.exists(DATA_PATH)}\")\n",
        "print(f\"U-Net model exists: {os.path.exists(UNET_MODEL_PATH)}\")\n",
        "print(f\"Mask R-CNN model exists: {os.path.exists(MASKRCNN_MODEL_PATH)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "def load_yolo_annotations(img_path, img_shape):\n",
        "    annotation_path = img_path.replace('images', 'labels').replace('.jpg', '.txt').replace('.png', '.txt')\n",
        "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
        "    \n",
        "    if os.path.exists(annotation_path):\n",
        "        try:\n",
        "            with open(annotation_path, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "            for line in lines:\n",
        "                data = line.strip().split()\n",
        "                if len(data) >= 5:\n",
        "                    x_center, y_center, width, height = map(float, data[1:5])\n",
        "                    h, w = img_shape[:2]\n",
        "                    x_center *= w\n",
        "                    y_center *= h\n",
        "                    width *= w\n",
        "                    height *= h\n",
        "                    x1 = max(0, int(x_center - width/2))\n",
        "                    y1 = max(0, int(y_center - height/2))\n",
        "                    x2 = min(w, int(x_center + width/2))\n",
        "                    y2 = min(h, int(y_center + height/2))\n",
        "                    if x2 > x1 and y2 > y1:\n",
        "                        mask[y1:y2, x1:x2] = 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {annotation_path}: {e}\")\n",
        "    return mask\n",
        "\n",
        "def load_test_data(data_path, img_size):\n",
        "    test_path = os.path.join(data_path, 'test', 'images')\n",
        "    image_files = sorted([f for f in os.listdir(test_path) if f.endswith(('.jpg', '.png'))])\n",
        "    \n",
        "    images = []\n",
        "    masks = []\n",
        "    filenames = []\n",
        "    \n",
        "    for filename in tqdm(image_files, desc=\"Loading test data\"):\n",
        "        img_path = os.path.join(test_path, filename)\n",
        "        image = cv2.imread(img_path)\n",
        "        if image is None:\n",
        "            continue\n",
        "        \n",
        "        original_shape = image.shape\n",
        "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image_resized = cv2.resize(image_rgb, img_size)\n",
        "        image_normalized = image_resized.astype(np.float32) / 255.0\n",
        "        \n",
        "        mask = load_yolo_annotations(img_path, original_shape)\n",
        "        mask_resized = cv2.resize(mask, img_size, interpolation=cv2.INTER_NEAREST)\n",
        "        \n",
        "        images.append(image_normalized)\n",
        "        masks.append(mask_resized)\n",
        "        filenames.append(filename)\n",
        "    \n",
        "    return np.array(images), np.array(masks), filenames\n",
        "\n",
        "print(\"Data loading functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
